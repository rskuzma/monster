{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert LDA Topics to d2v Vectors\n",
    "- Richard Kuzma, 8SEP2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LDA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "# basic\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "# data science\n",
    "import pandas as pd\n",
    "\n",
    "# NLP\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "\n",
    "# plotting\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save best perplexity model (8 topics)\n",
    "path = '/Users/richardkuzma/coding/analysis/monster/models/'\n",
    "\n",
    "filename = 'monster_jobs_LDA_40_topics_cv_zero476.pkl'\n",
    "with open(path+filename, 'rb') as f:\n",
    "    LDA_40 = pickle.load(f)\n",
    "    \n",
    "filename = 'monster_jobs_LDA_90_topics_cv_zero461.pkl'\n",
    "with open(path+filename, 'rb') as f:\n",
    "    LDA_90 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA with 30 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(best_model.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert KSB LDA Topics to vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load w2v KeyedVectors model trained on Google News\n",
    "Note, KeyedVectors models are not full models you can retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goog = gensim.models.KeyedVectors.load_word2vec_format('/Users/richardkuzma/coding/analysis/utils/GoogleNews-vectors-negative300.bin.gz', binary=True, limit=500000)\n",
    "print('loaded google w2v model of size 500,000 with dimension 300 vectors')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use LDA probability distribution to find the center vector of each topic\n",
    "\n",
    "pos_all = []\n",
    "total_missed_words = 0\n",
    "\n",
    "for i in range (0, best_model.num_topics): # for each LDA topic\n",
    "    print('\\n' + '-'*40 + 'Topic Number: {}'.format(i) + '-'*40 + '\\n')\n",
    "    missed_words = 0\n",
    "    pos_topic = []\n",
    "    for j in range(0, len(best_model.show_topic(i))): # for each words in a given topic\n",
    "        try:\n",
    "            # multiply w2v word vector by weight\n",
    "            pos_topic.append(goog[best_model.show_topic(i)[j][0]]*float(best_model.show_topic(i)[j][1]))\n",
    "            print('appended weighted vector for topic: {} and sub-word #{}: {} '.format(i, j, best_model.show_topic(i)[j][0]))\n",
    "        except KeyError:\n",
    "            print('Key error.......missed a word from topic: {}, number: {}, word: {}'.format(i,j,best_model.show_topic(i)[j][0]))\n",
    "            missed_words +=1 \n",
    "    \n",
    "    total_missed_words += missed_words\n",
    "    pos_all.append(pos_topic)\n",
    "    print('\\nappended pos_topic {} to pos_all'.format(i))\n",
    "    print('Missed {} words'.format(missed_words))\n",
    "    \n",
    "print('Missed words in total: {}'.format(total_missed_words))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### use weighted word vectors to find the top 20 most similar words for each topic\n",
    "\n",
    "similar_to_LDA_topics = []\n",
    "for i in range(0, best_model.num_topics):\n",
    "    similar_to_LDA_topics.append(goog.wv.most_similar(positive=pos_all[i], topn=15))\n",
    "\n",
    "from pprint import pprint\n",
    "for i in range(0, len(similar_to_LDA_topics)):\n",
    "    print('Topic #{} most similar words'.format(i))\n",
    "    pprint(similar_to_LDA_topics[i])\n",
    "    print('\\n\\n' +'*'*40 + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save 30-topic LDA model derived from 10,000 KSB aggregate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/richardkuzma/coding/analysis/monster/models/'\n",
    "filename = 'LDA_30_topics_10k_KSBs'\n",
    "\n",
    "with open(path+filename, 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model (by coherence):\n",
    "- LdaModel(num_terms=6107, <b>num_topics=30</b>, decay=0.5, chunksize=2000)\n",
    "- Coherence of <b>0.6807534740840404</b>\n",
    "- Saved to '/Users/richardkuzma/coding/analysis/monster/models/LDA_30_topics_10k_KSBs'\n",
    "\n",
    "Using a comprehensive list of 10,000 KSBs for LDA yields 20-30 topics that are too large. (e.g. 'supervisor', 'techincian', 'professional'. Will try to create separate LDA models for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
